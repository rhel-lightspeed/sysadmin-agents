# =============================================================================
# Sysadmin Agents Configuration
# =============================================================================
# Copy this file to config/.env and update with your values
# Or mount as ConfigMap in Kubernetes/Podman deployments
#
# Usage:
#   Local:  cp deploy/config.env.example .env
#   Podman: Mount as /opt/app-root/config/.env
# =============================================================================

# =============================================================================
# LLM Configuration (Required)
# =============================================================================

# Google API Key for Gemini models
# Get yours at: https://aistudio.google.com/app/apikey
GOOGLE_API_KEY=your-google-api-key-here

# Default model for agents
DEFAULT_MODEL=gemini-2.0-flash

# Optional: Different models for different roles
# DISPATCHER_MODEL=gemini-2.0-flash
# SPECIALIST_MODEL=gemini-2.0-flash

# =============================================================================
# MCP Server Configuration (linux-mcp-server)
# =============================================================================

# SSH username for connecting to RHEL servers
LINUX_MCP_USER=admin

# Path to SSH private key (inside container or mounted)
LINUX_MCP_SSH_KEY_PATH=/opt/app-root/src/.ssh/id_ed25519

# Log paths the agent is allowed to read (comma-separated)
LINUX_MCP_ALLOWED_LOG_PATHS=/var/log/messages,/var/log/secure,/var/log/audit/audit.log

# MCP server log level (DEBUG, INFO, WARNING, ERROR)
LINUX_MCP_LOG_LEVEL=INFO

# Optional: SSH key passphrase (if key is encrypted)
# LINUX_MCP_KEY_PASSPHRASE=

# =============================================================================
# Server Configuration
# =============================================================================

# Server port
PORT=8000

# Session storage URI
# SQLite (default, good for single-node):
SESSION_SERVICE_URI=sqlite+aiosqlite:///./sessions.db
# PostgreSQL (for production/multi-node):
# SESSION_SERVICE_URI=postgresql+asyncpg://user:pass@host:5432/dbname

# CORS allowed origins (comma-separated, or * for all)
ALLOWED_ORIGINS=*

# Enable ADK Web UI (true/false)
SERVE_WEB_UI=true

# =============================================================================
# Optional: Multi-Model Support (via LiteLLM)
# =============================================================================

# OpenAI API Key (for GPT-4, etc.)
# OPENAI_API_KEY=

# Anthropic API Key (for Claude, etc.)
# ANTHROPIC_API_KEY=

# =============================================================================
# Optional: Observability
# =============================================================================

# Enable observability (Langfuse integration)
# ENABLE_OBSERVABILITY=false
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_SECRET_KEY=
# LANGFUSE_HOST=https://cloud.langfuse.com

